#set text(size: 15pt, font: ("Arial","Source Han Serif SC"))
= 信息熵
对于一个十进制数$x$,所需表示的位数是$log_2^(abs(x))+1$\
那对于n个数字的数据集呢？是不是$n dot [log_2^(abs(x))+1]$吗？
错的，我们其实不需要那么多bits

+ 数据越混乱，我们所需描述它所用的信息量就越大
+ 似乎可以通过在数据出现的频率上做文章，来实现数据的压缩
- 香农的信息熵的公式
$ H(x)=-sum p(x_i) log_2(p(x_i)) $
#figure(caption: [信息熵的例子])[#image("image.png")]
信息熵的意义：平均每个数据需要$H(x)$个二进制位才能表示这个数据集
= 变长编码
给出现概率搞的符号分配最小的位数，给出现概率低的符号分配最多的位数，可以实现压缩
+ 遍历每个符号并计算概率
+ 根据概率计算码字，概率越大分配的码字越短（注意避免前缀重复）
+ 再次遍历进行编码（形成串）
有很多问题，不按字节或者整形对齐，对于大数值，码字长度的增长速度一般会超过$log_2^n$个二进制位，解码速度慢，每次智能读取一个二进制位

分配码字是一个很复杂很重要的过程，如果码字选的不好，似乎会导致压缩失败，那么有没有一套成熟的理论，现成的办法可以供我们直接使用去分配码字呢？
== Huffman编码
一个数据集，仅由'A','B','C','D','E'字符组成，它们的频次是15,7,6,6,5

构造数，详细见: #link("https://hardcore.feishu.cn/docx/I685dBe9yokEfgxpMFWcJep4nye","教程")
== LZW编码
核心思想：把出现过的字符串映射到记号上，这样就可以用较短的编码表示长的字符串，实现压缩，例如对于:\
ABABAB，可以表示为\
AB22\
2是 zizizi